<!doctype html><html dir=ltr lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,minimum-scale=1,maximum-scale=5"><title>Container Alerts | Aurora
</title><link rel=icon href=/favicon.ico type=image/x-icon><link rel=preload href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css as=style crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.design-system.alpha.canada.ca/@cdssnc/gcds-utility@1.10.0/dist/gcds-utility.min.css><link rel=stylesheet href=https://cdn.design-system.alpha.canada.ca/@cdssnc/gcds-components@0.42.0/dist/gcds/gcds.css><script async type=module src=https://cdn.design-system.alpha.canada.ca/@cdssnc/gcds-components@0.42.0/dist/gcds/gcds.esm.js></script><link rel=stylesheet href=/scss/main.css><link rel=stylesheet href=/scss/custom.css><style>html{font-size:16px}body{font-size:var(--gcds-font-sizes-text);line-height:var(--gcds-line-heights-text);color:var(--gcds-color-grayscale-1000);font-family:var(--gcds-font-families-body),sans-serif;margin:0;animation:fade .05s forwards ease-in-out}</style><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/glightbox/dist/css/glightbox.min.css></head><body style=margin:0 class=character-limit><main><gcds-container centered size=md><gcds-text size=caption style="text-align: center;"><strong>Alpha</strong>&nbsp;&nbsp;This is an experimental service.</gcds-text>
</gcds-container><gcds-header lang=en lang-href signature-variant=colour skip-to-href=#><gcds-search lang=en slot=search action=/sr/srb.html placeholder=Aurora></gcds-search><gcds-top-nav slot=menu label="Top navigation" alignment=right><gcds-nav-link href=/ slot=home>GC Cloud One: Aurora
</gcds-nav-link><gcds-nav-group open-trigger=Platform menu-label=Platform><gcds-nav-link href=/proposal>Proposal
</gcds-nav-link><gcds-nav-link href=/vision>Vision
</gcds-nav-link><gcds-nav-link href=/architecture>Architecture
</gcds-nav-link></gcds-nav-group><gcds-nav-group open-trigger=Team menu-label=Team><gcds-nav-link href=/team/sop>Standard Operating Procedures
</gcds-nav-link><gcds-nav-link href=/team/monitoring-alerts/>Monitoring
</gcds-nav-link><gcds-nav-link href=/team/appendix>Appendix
</gcds-nav-link></gcds-nav-group><gcds-nav-group open-trigger=Community menu-label=Community><gcds-nav-link href=/get-involved>Get involved
</gcds-nav-link><gcds-nav-link href=/rules-of-engagement>Rules of Engagement
</gcds-nav-link><gcds-nav-link href=/technical-advisory-group>Technical Advisory Group
</gcds-nav-link></gcds-nav-group><gcds-nav-link href=/contact slot>Contact us
</gcds-nav-link></gcds-top-nav><gcds-breadcrumbs slot=breadcrumb><gcds-breadcrumbs-item href="https://hosting-services-hebergement.canada.ca/s/gc-cloud-one?language=en_US">GC Cloud One</gcds-breadcrumbs-item>
<gcds-breadcrumbs-item href=/>Aurora</gcds-breadcrumbs-item>
<gcds-breadcrumbs-item href=/team/>Team Guide</gcds-breadcrumbs-item>
<gcds-breadcrumbs-item href=/team/monitoring-alerts/>Monitoring and Alerting</gcds-breadcrumbs-item>
<gcds-breadcrumbs-item href=/team/monitoring-alerts/alert-namespace-level/>Namespace Level Alerts</gcds-breadcrumbs-item>
</gcds-breadcrumbs></gcds-header><gcds-container size=xl main-container centered tag=main><gcds-grid tag=section columns=1fr columns-desktop="
        1fr 3fr
      " align-items=start class=hydrated><aside role=complementary><gcds-side-nav label="Team Guide"><gcds-nav-link href=/team/>Team Guide
</gcds-nav-link><gcds-nav-group open-trigger="Standard Operating Procedures" menu-label="Standard Operating Procedures"><gcds-nav-link href=/team/standard-operating-procedures/>Standard Operating Procedures
</gcds-nav-link><gcds-nav-link href=/team/standard-operating-procedures/backup-disaster-recovery/>Backup and Disaster Recovery
</gcds-nav-link><gcds-nav-link href=/team/standard-operating-procedures/bootstrap-cluster/>Bootstrap Cluster
</gcds-nav-link><gcds-nav-link href=/team/standard-operating-procedures/infrastructure-and-configuration-management/>Infrastructure and Configuration Management
</gcds-nav-link><gcds-nav-link href=/team/standard-operating-procedures/issue-naming/>Issue and PR Naming Conventions
</gcds-nav-link><gcds-nav-link href=/team/standard-operating-procedures/enterprise-landing-zone/>Onboarding process for the Enterprise Landing Zone
</gcds-nav-link></gcds-nav-group><gcds-nav-group open-trigger="Monitoring and Alerting" menu-label="Monitoring and Alerting" open><gcds-nav-link href=/team/monitoring-alerts/>Monitoring and Alerting
</gcds-nav-link><gcds-nav-link href=/team/monitoring-alerts/prometheus/>Prometheus
</gcds-nav-link><gcds-nav-link href=/team/monitoring-alerts/prometheus-operator/>Prometheus Operator
</gcds-nav-link><gcds-nav-link href=/team/monitoring-alerts/alertmanager/>Alertmanager
</gcds-nav-link><gcds-nav-link href=/team/monitoring-alerts/blackbox-exporter/>Blackbox Exporter
</gcds-nav-link><gcds-nav-group open-trigger="Cluster Level Alerts" menu-label="Cluster Level Alerts"><gcds-nav-link href=/team/monitoring-alerts/alert-cluster-level/>Cluster Level Alerts
</gcds-nav-link><gcds-nav-link href=/team/monitoring-alerts/alert-cluster-level/cert-manager/>Cert Manager Alerts
</gcds-nav-link><gcds-nav-link href=/team/monitoring-alerts/alert-cluster-level/node/>Node Alerts
</gcds-nav-link><gcds-nav-link href=/team/monitoring-alerts/alert-cluster-level/node-pool-pod-capacity/>Node Pool Capacity Alerts
</gcds-nav-link><gcds-nav-link href=/team/monitoring-alerts/alert-cluster-level/probe-failure/>Probe Failure Alerts
</gcds-nav-link><gcds-nav-link href=/team/monitoring-alerts/alert-cluster-level/prometheus-storage-low/>Prometheus Storage Alerts
</gcds-nav-link><gcds-nav-link href=/team/monitoring-alerts/alert-cluster-level/ssl-cert-expiring-soon/>SSL Certificate Alerts
</gcds-nav-link><gcds-nav-link href=/team/monitoring-alerts/alert-cluster-level/velero/>Velero Alerts
</gcds-nav-link></gcds-nav-group><gcds-nav-group open-trigger="Namespace Level Alerts" menu-label="Namespace Level Alerts" open><gcds-nav-link href=/team/monitoring-alerts/alert-namespace-level/>Namespace Level Alerts
</gcds-nav-link><gcds-nav-link href=/team/monitoring-alerts/alert-namespace-level/container/ current=true>Container Alerts
</gcds-nav-link><gcds-nav-link href=/team/monitoring-alerts/alert-namespace-level/job/>Job Alerts
</gcds-nav-link><gcds-nav-link href=/team/monitoring-alerts/alert-namespace-level/persistent-volume-claims/>Persistent Volume Claim Alerts
</gcds-nav-link><gcds-nav-link href=/team/monitoring-alerts/alert-namespace-level/pod-not-ready/>Pod Alerts
</gcds-nav-link></gcds-nav-group></gcds-nav-group><gcds-nav-group open-trigger=Appendix menu-label=Appendix><gcds-nav-link href=/team/appendix/>Appendix
</gcds-nav-link><gcds-nav-link href=/team/appendix/acronyms/>Acronyms
</gcds-nav-link><gcds-nav-link href=/team/appendix/lexicon/>Lexicon</gcds-nav-link></gcds-nav-group></gcds-side-nav></aside><section class=mb-400><gcds-heading tag=h1>Container Alerts</gcds-heading>
<gcds-alert alert-role=danger container=full heading="Avis de traduction" hide-close-btn=true hide-role-icon=false is-fixed=false class="hydrated mb-400"><gcds-text>Veuillez noter que ce document est actuellement en cours de développement actif et pourrait être sujet à des révisions. Une fois terminé, il sera entièrement traduit en français et mis à disposition dans sa version finale.</gcds-text>
</gcds-alert><gcds-heading tag=h2 id=alert-containerlowcpu character-limit=true>Alert: ContainerLowCPU<gcds-link href=#alert-containerlowcpu class=pilcrow>¶</gcds-link></gcds-heading>
<gcds-text character-limit=true>This alert occurs at the namespace-level within a cluster. This alert will be triggered by default when a container is using up more than <strong>85%</strong> of its allotted CPU for more than a <strong>five</strong> minute period.</gcds-text>
<gcds-text character-limit=true>This alert is triggered by a pod using almost all the CPU allocated for it. When introducing a new workload or migrating an existing workload to Kubernetes, you may not be aware of the resources required. Kubernetes works best when resource restrictions and requests are established for each pod (or, more correctly, each container in each pod). Pod CPU usage is the aggregate of the CPU use of all containers in a pod.</gcds-text>
<gcds-text character-limit=true>Note that high CPU usage by a pod can lead to it being throttled.</gcds-text>
<gcds-text character-limit=true>To resolve this alert, teams can investigate the container in question to address the pod CPU usage.</gcds-text>
<gcds-heading tag=h3 id=resolution-process character-limit=true>Resolution Process<gcds-link href=#resolution-process class=pilcrow>¶</gcds-link></gcds-heading><ol><li><gcds-text character-limit=true>Identify which pods currently have the highest CPU utilization: <em>(Note that 1000m equates to 1 Azure vCore)</em></gcds-text>
<gcds-text character-limit=true><code>kubectl top pod --sort-by=cpu -n &lt;namespace></code></gcds-text></li><li><gcds-text character-limit=true>Investigate any unusual events in the logs for each container and check codebase:</gcds-text>
<gcds-text character-limit=true><code>kubectl logs &lt;podName> -c &lt;containerName> -n &lt;namespace></code></gcds-text></li><li><gcds-text character-limit=true>Check historic CPU utilization of the pod in Grafana or Prometheus graphs and look for potential optimizations to be made (i.e. requests)</gcds-text></li><li><gcds-text character-limit=true>Furthermore, describing the pod and checking its state can yield more information:</gcds-text>
<gcds-text character-limit=true><code>kubectl describe pod &lt;podName> -n &lt;namespace></code></gcds-text></li><li><gcds-text character-limit=true>As necessary, increase the <strong>requests</strong> CPU and <strong>limits</strong> CPU. Note that requests are what the container is guaranteed to get, whereas, limits, on the other hand, is the resource threshold a container can never exceed. Setting the request of CPU more than any of the cluster nodes can handle will cause the container to be in a pending state indefinitely until there is a large enough node. You can check the nodes used by the namespace:</gcds-text>
<gcds-text character-limit=true><code>kubectl top node -n &lt;namespace></code></gcds-text></li><li><gcds-text character-limit=true>Ideally, teams should always
<gcds-link href=https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>set limits and resources</gcds-link> for their pods. However, at the namespace level,
<gcds-link href=https://kubernetes.io/docs/concepts/policy/resource-quotas/>ResourceQuotas</gcds-link> and
<gcds-link href=https://kubernetes.io/docs/concepts/policy/limit-range/>LimitRanges</gcds-link> are oftentimes defined.</gcds-text></li></ol><gcds-heading tag=h3 id=additional-troubleshooting character-limit=true>Additional Troubleshooting<gcds-link href=#additional-troubleshooting class=pilcrow>¶</gcds-link></gcds-heading><ul><li><gcds-text character-limit=true>Avoid over-provisioning since you could be using a lot more resources than your workload might need. If you are using a production and development namespace, avoid defining quotas on the production namespace and define strict quotas on the development namespace. This will help you to avoid your production containers being throttled because your development environment required more resources.</gcds-text></li><li><gcds-text character-limit=true>Take this opportunity to reflect on your application architecture and application scalability. The platform enables users to horizontally scale the total containers used based on their application requirements, which may change over time. This can be done with the help of a
<gcds-link href=https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/><em>Horizontal Pod Autoscaler</em></gcds-link>. The use of a HorizontalPodAutoscaler can increase capacity and reduce overall load. It is a useful tool for dealing with resource issues or bursting of workloads since it can also act upon CPU usage.</gcds-text></li></ul><gcds-heading tag=h2 id=alert-containerlowmemory character-limit=true>Alert: ContainerLowMemory<gcds-link href=#alert-containerlowmemory class=pilcrow>¶</gcds-link></gcds-heading>
<gcds-text character-limit=true>This alert occurs at the namespace-level within a cluster. This alert will be triggered by default when a container is using up more than <strong>80%</strong> of its allotted memory for more than a <strong>two</strong> minute period.</gcds-text>
<gcds-text character-limit=true>This alert is often triggered by a pod with high memory usage relative to the amount of memory allocated for it. When introducing a new workload or migrating an existing workload to Kubernetes, you may not be aware of the resources required. Kubernetes works best when resource restrictions and requests are established for each pod (or, more correctly, each container in each pod). Memory utilization refers to the total aggregate of memory used by all containers in a pod.</gcds-text>
<gcds-text character-limit=true>Note that high memory utilization requires remediation as soon as possible. Containers that reach their memory limits get OOMKilled.
To resolve this alert, teams must debug the container in question to resolve the high memory utilization.</gcds-text>
<gcds-heading tag=h3 id=resolution-process-1 character-limit=true>Resolution Process<gcds-link href=#resolution-process-1 class=pilcrow>¶</gcds-link></gcds-heading><ol><li><gcds-text character-limit=true>Identify which pods currently have the highest memory utilization:</gcds-text>
<gcds-text character-limit=true><code>kubectl top pod --sort-by=memory -n &lt;namespace></code></gcds-text></li><li><gcds-text character-limit=true>Check for memory leaks by investigating events in the logs for each container:</gcds-text>
<gcds-text character-limit=true><code>kubectl logs &lt;podName> -c &lt;containerName> -n &lt;namespace></code></gcds-text></li><li><gcds-text character-limit=true>Check historic memory usage of the pod in Grafana or Prometheus graphs and look for potential optimizations to be made (i.e. requests)</gcds-text></li><li><gcds-text character-limit=true>Furthermore, describing the pod and checking its state can yield more information:</gcds-text>
<gcds-text character-limit=true><code>kubectl describe pod &lt;podName> -n &lt;namespace></code></gcds-text></li><li><gcds-text character-limit=true>As necessary, increase the <strong>requests</strong> memory and <strong>limits</strong> memory. Note that requests are what the container is guaranteed to get, whereas, limits, on the other hand, is the resource threshold a container can never exceed. Setting the request of memory more than any of the cluster nodes can handle will make the container in the pending state indefinitely until there is a large enough node. You can check the nodes used by the namespace:</gcds-text>
<gcds-text character-limit=true><code>kubectl top node -n &lt;namespace></code></gcds-text></li><li><gcds-text character-limit=true>Ideally, teams should always
<gcds-link href=https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>set limits and resources</gcds-link> for their pods. However, at the namespace level,
<gcds-link href=https://kubernetes.io/docs/concepts/policy/resource-quotas/>ResourceQuotas</gcds-link> and
<gcds-link href=https://kubernetes.io/docs/concepts/policy/limit-range/>LimitRanges</gcds-link> are oftentimes defined.</gcds-text></li><li><gcds-text character-limit=true>Check to see if the pod has multiple restarts. Oftentimes, containers that reach their memory limits get OOMKilled and trigger a restart.</gcds-text>
<gcds-text character-limit=true><code>kubectl get pods -n &lt;namespace> --sort-by='.status.containerStatuses[0].restartCount'</code></gcds-text></li></ol><gcds-heading tag=h3 id=additional-troubleshooting-1 character-limit=true>Additional Troubleshooting<gcds-link href=#additional-troubleshooting-1 class=pilcrow>¶</gcds-link></gcds-heading><ul><li><gcds-text character-limit=true>Avoid over-provisioning since you could be using a lot more resources than your workload might need. If you are using a production and development namespace, avoid defining quotas on the production namespace and define strict quotas on the development namespace. This will help you to avoid your production containers being evicted because your development environment required more resources.</gcds-text></li><li><gcds-text character-limit=true>Take this opportunity to reflect on your application architecture and application scalability. The platform enables users to horizontally scale the total containers used based on their application requirements, which may change over time. This can be done with the help of a
<gcds-link href=https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/><em>Horizontal Pod Autoscaler</em></gcds-link>. The use of a HorizontalPodAutoscaler can increase capacity and reduce overall load. It is a useful tool for dealing with resource issues or bursting of workloads since it can also act upon memory usage.</gcds-text></li></ul><gcds-heading tag=h2 id=alert-containerwaiting character-limit=true>Alert: ContainerWaiting<gcds-link href=#alert-containerwaiting class=pilcrow>¶</gcds-link></gcds-heading>
<gcds-text character-limit=true>This alert occurs at the Namespace level. This alert is triggered when a container has been in the <em>Waiting</em> state for a period of time exceeding <strong>15 minutes</strong>.</gcds-text>
<gcds-text character-limit=true>According to Kubernetes
<gcds-link href=https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/>Pod Lifecycle</gcds-link> specifications, a container can either be in the <em>Running</em>, <em>Terminated</em>, or <em>Waiting</em> state. If a container is not in either the Running or Terminiated state, it is Waiting. A container in the Waiting state is still in the process of running the operations it requires in order to complete start up. (e.g pulling the container image from a container image registry, or applying Secret data).</gcds-text>
<gcds-heading tag=h3 id=resolution-process-2 character-limit=true>Resolution Process<gcds-link href=#resolution-process-2 class=pilcrow>¶</gcds-link></gcds-heading><ol><li><gcds-text character-limit=true>You can view the Pod status using kubectl. When listing the Pods you should see a Status field in the output:</gcds-text>
<gcds-text character-limit=true><code>kubectl get pods -n &lt;namespace></code></gcds-text></li><li><gcds-text character-limit=true>Describe the pod with the Waiting container. You should see a Reason field that summarizes the behaviour:</gcds-text>
<gcds-text character-limit=true><code>kubectl describe pod &lt;podName> -n &lt;namespace></code></gcds-text></li><li><gcds-text character-limit=true>Investigate any unusual events in the logs for the container:</gcds-text>
<gcds-text character-limit=true><code>kubectl logs &lt;podName> -c &lt;containerName> -n &lt;namespace></code></gcds-text></li></ol><gcds-heading tag=h3 id=additional-troubleshooting-2 character-limit=true>Additional Troubleshooting<gcds-link href=#additional-troubleshooting-2 class=pilcrow>¶</gcds-link></gcds-heading>
<gcds-text character-limit=true>Pods can have multiple statuses causing them to be in the non ready state. The list below covers the most common statuses:</gcds-text>
<gcds-heading tag=h4 id=containercreating character-limit=true>ContainerCreating<gcds-link href=#containercreating class=pilcrow>¶</gcds-link></gcds-heading>
<gcds-text character-limit=true>ContainerCreating implies that kube-scheduler has assigned a worker node for the container and has instructed the container runtime to kick-off the workload. However, note that the network is not provisioned at this stage — i.e, the workload does not have an IP address. Common reasons why your Pod might get stuck in the ContainerCreating stage:</gcds-text><ol><li>Failure in IP address allocation</li><li>Failure to mount ConfigMaps</li><li>Failure to claim Persistent Volumes</li></ol><gcds-heading tag=h4 id=createcontainerconfigerror character-limit=true>CreateContainerConfigError<gcds-link href=#createcontainerconfigerror class=pilcrow>¶</gcds-link></gcds-heading>
<gcds-text character-limit=true>A Pod falls in a CreateContainerConfigError status when Kubernetes tries to create a container in a pod, but fails before the container enters the Running state. Some common causes of this error are as follows:</gcds-text><ul><li><strong>ConfigMap is missing</strong> — a ConfigMap stores configuration data such as key-value pairs. You must identify the missing ConfigMap and create it in the namespace, or mount another, existing ConfigMap.</li><li><strong>Secret is missing</strong> — a Secret is used to store sensitive information such as credentials. You must identify the missing Secret and create it in the namespace, or mount another, existing Secret.</li></ul><gcds-heading tag=h4 id=createcontainererror character-limit=true>CreateContainerError<gcds-link href=#createcontainererror class=pilcrow>¶</gcds-link></gcds-heading>
<gcds-text character-limit=true>This issue occurs when Kubernetes tries to create a container but fails. It implies some sort of issue with the container runtime, but can also indicate a problem starting up the container, such as the command not existing. This symptom can also lead to
<gcds-link href=#many-container-restarts>CrashLoopBackOff</gcds-link> errors.</gcds-text>
<gcds-text character-limit=true>Examine the Events in the pod:
<code>kubectl describe pod &lt;podName> -n &lt;namespace></code></gcds-text><ol><li><strong>&ldquo;no command specified&rdquo;</strong> implies the error is caused by both the image and pod specification not specifying a command to run.</li><li><strong>&ldquo;starting container process caused&rdquo;</strong> indicates that the starting command might not be available on the image. Rectify the container start command or the image&rsquo;s contents accordingly.</li><li><strong>&ldquo;container name [&mldr;] already in use by container&rdquo;</strong> means that there is a problem with the container runtime on that host not cleaning up old containers. If you have admin access, verify the kubelet logs on the node the container was assigned to.</li><li><strong>"&mldr;is waiting to start"</strong> means the issue may have to do with Volumes/Secrets mounting. If there is an Init container, then look at the logs, as it may be responsible for provisioning the volume.</li></ol><gcds-text character-limit=true>Check any secrets and/or configmaps in the pod are available to your pods in your namespace.</gcds-text>
<gcds-heading tag=h4 id=errimagepull character-limit=true>ErrImagePull<gcds-link href=#errimagepull class=pilcrow>¶</gcds-link></gcds-heading>
<gcds-text character-limit=true>The image could not be pulled from the repository.</gcds-text><ol><li>Verify that the image repository exists.</li><li>Verify that you have correct access to the repository.</li><li>Verify that the repository and image names are spelled correctly.</li></ol><gcds-heading tag=h4 id=imagepullbackoff character-limit=true>ImagePullBackOff<gcds-link href=#imagepullbackoff class=pilcrow>¶</gcds-link></gcds-heading>
<gcds-text character-limit=true>This error appears when Kubernetes is not able to retrieve the image for one of the containers of the Pod.
There are three common culprits:</gcds-text><ol><li>The image name is invalid — for example, the image name was misspelt, or the image does not exist.</li><li>A non-existing tag was specified for the image.</li><li>The Artifactory credentials (managed by the Cloud Native Solutions team) stored in the artifactory-prod secret does not have access to the specified image.</li></ol><gcds-heading tag=h4 id=invalidimagename character-limit=true>InvalidImageName<gcds-link href=#invalidimagename class=pilcrow>¶</gcds-link></gcds-heading>
<gcds-text character-limit=true>The container cannot pull the image due to an invalid image name. The image name cannot be found in the local or remote Artifactory repositories:</gcds-text><ul><li>Verify that the correct image name (registry and image) is being used:
<code>kubectl describe pod &lt;podName> -n &lt;namespace></code></li><li>Verify in the source code</li></ul><gcds-heading tag=h2 id=alert-manycontainerrestarts character-limit=true>Alert: ManyContainerRestarts<gcds-link href=#alert-manycontainerrestarts class=pilcrow>¶</gcds-link></gcds-heading>
<gcds-text character-limit=true>This alert occurs at the Namespace-level within a cluster. This alert will be triggered when a container is subject to frequent restarts within a specified time period. (10 restarts in the last 8 hours) This alert is often triggered by a Pod that is stuck in the CrashLoopBackoff state, where a container may see many restarts in a small time window (minutes).</gcds-text>
<gcds-text character-limit=true>To resolve this alert, users must properly debug the flagged container to remediate the frequent restarts.</gcds-text>
<gcds-heading tag=h3 id=resolution-process-3 character-limit=true>Resolution Process<gcds-link href=#resolution-process-3 class=pilcrow>¶</gcds-link></gcds-heading><ol><li><gcds-text character-limit=true>Investigate Pod Logs:</gcds-text>
<gcds-text character-limit=true><code>kubectl -n &lt;Namespace> logs &lt;PodName> -c &lt;ContainerName></code></gcds-text></li><li><gcds-text character-limit=true>Additionally, you can check the previously exited Pod Logs:</gcds-text>
<gcds-text character-limit=true><code>kubectl -n &lt;Namespace> logs -p &lt;PodName> -c &lt;ContainerName></code></gcds-text></li><li><gcds-text character-limit=true>You can also <strong>describe</strong> the Pod and check for useful information:</gcds-text>
<gcds-text character-limit=true><code>kubectl -n &lt;Namespace> describe pod &lt;PodName></code></gcds-text><ul><li>Check the Pod Events</li><li>Check for last terminated reason</li></ul></li><li><gcds-text character-limit=true>Research (Google) any error codes or messages. Apply remediation steps.</gcds-text><ul><li>Example: for Out-Of-Memory (OOM) errors, adjust the container resource limits to increase memory and/or check the application code for any potential memory leaks.</li></ul></li></ol><gcds-date-modified lang=en>0001-01-01</gcds-date-modified></section></gcds-grid></gcds-container></main><gcds-footer lang=en display=compact contextual-heading=Aurora contextual-links='{ "Contact us": "/contact","Report an issue": "https://github.com/gccloudone/aurora/issues/new/choose","About us": "/about" }'></gcds-footer><script src=https://cdn.jsdelivr.net/npm/glightbox/dist/js/glightbox.min.js></script><script>const style=document.createElement("style");style.innerHTML=`
    .glightbox-container.glightbox-custom-white-bg img {
      background: white !important;
    }
  `,document.head.appendChild(style);const lightbox=GLightbox({openEffect:"zoom",closeEffect:"fade",skin:"custom-white-bg"})</script></body></html>